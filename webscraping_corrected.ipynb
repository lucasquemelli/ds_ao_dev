{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ce4c3b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035c8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import math\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a16c1",
   "metadata": {},
   "source": [
    "# Data Collection (products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c90c750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL\n",
    "url01 = \"https://www2.hm.com/en_us/men/products/jeans.html?sort=stock&image-size=small&image=model&offset=0&page-size=72\"\n",
    "\n",
    "# Parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# Request to URL\n",
    "page = requests.get(url01, headers=headers)\n",
    "\n",
    "# Beautiful Soup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "# ========================= Product Data ====================== #\n",
    "\n",
    "# List which contains all products\n",
    "products = soup.find('ul', 'products-listing small')\n",
    "  \n",
    "# product_id_categort list\n",
    "product_id_category = products.find_all('article', 'hm-product-item')\n",
    "\n",
    "# product_name list\n",
    "product_name = products.find_all('a', 'link')\n",
    "\n",
    "# product_price list\n",
    "product_price = products.find_all('span', 'price regular')\n",
    "\n",
    "product_id = [p.get('data-articlecode') for p in product_id_category]\n",
    "product_category = [p.get('data-category') for p in product_id_category]\n",
    "product_name = [p.get_text() for p in product_name]\n",
    "product_price = [p.get_text() for p in product_price]\n",
    "\n",
    "data = pd.DataFrame([product_id, product_name, product_category, product_price]).T\n",
    "data.columns = ['id', 'product_name', 'product_type', 'price']\n",
    "\n",
    "data['scrape_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8d6084",
   "metadata": {},
   "source": [
    "# Data Collection (inside each product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4fe67c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m df_composition \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(product_composition)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Columns name\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m df_composition\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m \u001b[43mdf_composition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Filling None/NA values\u001b[39;00m\n\u001b[1;32m     56\u001b[0m df_composition \u001b[38;5;241m=\u001b[39m df_composition\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mfillna(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mffill\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_ao_dev_env/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_ao_dev_env/lib/python3.9/site-packages/pandas/core/indexing.py:1523\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1523\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ds_ao_dev_env/lib/python3.9/site-packages/pandas/core/indexing.py:1455\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1453\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "#empty dataframe\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# All columns found on website\n",
    "cols = ['Art. No.', 'Composition', 'Fit', 'More sustainable materials', 'Size']\n",
    "df_pattern = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(data)):\n",
    "\n",
    "    #API request\n",
    "    # conteúdo de headers é padrão\n",
    "    url02 = \"https://www2.hm.com/en_us/productpage.\" + data.loc[i, 'id'] + \".html\"\n",
    "\n",
    "    page = requests.get(url02, headers=headers)\n",
    "\n",
    "    #Beautiful Soup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # ============================= Color =========================\n",
    "\n",
    "    #product list\n",
    "    product_list = soup.find_all('a', role='radio')\n",
    "\n",
    "    #color\n",
    "    product_color = [p.get('data-color') for p in product_list] \n",
    "\n",
    "    #id\n",
    "    product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "    #dataframe\n",
    "    df_color = pd.DataFrame([product_id, product_color]).T\n",
    "    df_color.columns = ['id', 'color']\n",
    "\n",
    "    #generate style id + color id\n",
    "    df_color['style_id'] = df_color['id'].apply(lambda x: x[:-3])\n",
    "    df_color['color_id'] = df_color['id'].apply(lambda x: x[-3:])\n",
    "\n",
    "    # ============================ Composition =====================\n",
    "\n",
    "    # Product list\n",
    "    product_composition_list = soup.find_all('div', 'pdp-description-list-item')\n",
    "\n",
    "    # Composition\n",
    "    product_composition = [list( filter( None, p.get_text().split('\\n') ) ) for p in product_composition_list]\n",
    "\n",
    "\n",
    "    # dataframe\n",
    "    df_composition = pd.DataFrame(product_composition).T\n",
    "\n",
    "    # Columns name\n",
    "    df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "    # Filling None/NA values\n",
    "    df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "        \n",
    "    # The same number of columns (pattern)\n",
    "    df_composition = pd.concat( [df_pattern, df_composition] )\n",
    "\n",
    "    # Generate Style ID + Color ID\n",
    "    # All values, but the last three values\n",
    "    df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "    df_composition['color_id'] = df_composition['Art. No.'].apply(lambda x: x[-3:])\n",
    "\n",
    "    # ======================= Merging color + composition ==========================\n",
    "    data_merge = pd.merge(df_color, df_composition[['style_id', 'Fit', 'Composition', 'More sustainable materials', 'Size']], how='left', on='style_id')\n",
    "\n",
    "    # ======================= Concatenate ==========================================\n",
    "    df_final = pd.concat( [df_final, data_merge], axis=0 )\n",
    "        \n",
    "# Creating style_id + color_id\n",
    "data['style_id'] = data['id'].apply(lambda x: x[:-3])\n",
    "data['color_id'] = data['id'].apply(lambda x: x[-3:])\n",
    "\n",
    "data_raw = pd.merge( data, df_final[['color', 'style_id', 'Fit', 'Composition', 'More sustainable materials', 'Size']], how='left', on='style_id')\n",
    "    \n",
    "data_raw.to_csv(\"data_raw.csv\")\n",
    "\n",
    "data_merge(data, df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30454f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/lucasquemelli/ds_ao_dev/main/data_raw.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "data['product_name'] = data['product_name'].apply(lambda x: x.replace(' ', '_').lower() )\n",
    "\n",
    "data['price'] = data['price'].apply(lambda x: x.replace('$ ', '')).astype(float)\n",
    "\n",
    "data['scrape_datetime'] = pd.to_datetime(data['scrape_datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data['color'] = data['color'].apply(lambda x: x.replace(' ', '_').replace('/', '_').replace('-', '_').lower() )\n",
    "\n",
    "data['Fit'] = data['Fit'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "data = data[~data['Composition'].str.contains('Pocket lining:')]\n",
    "data = data[~data['Composition'].str.contains('Lining:')]\n",
    "data = data[~data['Composition'].str.contains('Shell:')]\n",
    "data = data[~data['Composition'].str.contains('Pocket:')]\n",
    "\n",
    "# To remove duplicates that are not considered because Na in 'compositions' columns, we selected all columns before\n",
    "data = data.drop_duplicates(subset=['id', 'product_name', 'product_type', 'price', 'datetime',\n",
    "                                        'style_id', 'color_id', 'color', 'Fit'], keep='last')\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "df1 = data['Composition'].str.split(',', expand=True)\n",
    "\n",
    "df_ref = pd.DataFrame(index=np.arange(len(data)), columns=['Cotton', 'Polyester', 'Spandex'])\n",
    "\n",
    "# Cotton\n",
    "df_cotton = df1[0]\n",
    "df_cotton.name = 'cotton'\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated()]\n",
    "df_ref = df_ref.drop(columns=['Cotton'], axis=1) \n",
    "df_ref['cotton'] = df_ref['cotton'].fillna('Cotton 0%')\n",
    "\n",
    "# Polyester\n",
    "df_polyester = df1.loc[df1[1].str.contains('Polyester', na=True), 1]\n",
    "df_polyester.name = 'polyester'\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "df_ref = df_ref.drop(columns=['Polyester'], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated()] \n",
    "df_ref['polyester'] = df_ref['polyester'].fillna('Polyester 0%')\n",
    "\n",
    "# Spandex\n",
    "df_spandex = df1.loc[df1[1].str.contains('Spandex', na=True), 1]\n",
    "df_spandex.name = 'spandex'\n",
    "df_spandex = df_spandex.combine_first(df1[2])\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "df_ref = df_ref.drop(columns=['Spandex'], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated()]\n",
    "df_ref['spandex'] = df_ref['spandex'].fillna('Spandex 0%')\n",
    "\n",
    "data = pd.concat([data.reset_index(), df_ref.reset_index()], axis=1)\n",
    "data = data.drop(columns=['index', 'Unnamed: 0'], axis=1)\n",
    "data = data.iloc[:, ~data.columns.duplicated()]\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "data['cotton'] = data['cotton'].apply(lambda x: int( re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "data['polyester'] = data['polyester'].apply(lambda x: int( re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "data['spandex'] = data['spandex'].apply(lambda x: int( re.search('\\d+', x).group(0))/100 if pd.notnull(x) else x)\n",
    "\n",
    "\n",
    "data['model_size'] = data['Size'].apply(lambda x: re.search('\\d{3}', x).group(0) if pd.notnull(x) else x).astype(float)\n",
    "data['jeans_size'] = data['Size'].str.extract('(\\d+/\\\\d+)')\n",
    "       \n",
    "data = data.drop(columns=['Size'], axis=1)\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "data.to_csv(\"data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466496df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
